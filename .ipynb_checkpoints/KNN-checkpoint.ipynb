{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Accuracy of a classifier -> train and test. test shouldnt be a subset of train obviously. But dividing a dataset into train and test has its problems -> probability that the train subset of the data will uniformly represent all data. SRS can turn out to be an improbable ideal scenario. "
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Solution -> repeat the process a number of times and average the result. Ideally, 10 parts are used -> 10-Fold Cross Validation. randomly divide dataset into 10 parts. repeat 10 times with a different test block everytime. then average the accuracy. "
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evaluating classifiers -> % OR confusion matrix -> every row is the actual class of the test and every column is the predicted class using the classifier. This way, we acn see where exactly the classifier is inaccurate."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def buckets(filename, bucketName, separator, classColumn):\n",
      "    # classColumn is the column of the class associated with the data(line)\n",
      "    \"\"\"the original data is in the file named filename\n",
      "    bucketName is the prefix for all the bucket names\n",
      "    separator is the character that divides the columns\n",
      "    (for ex., a tab or comma and classColumn is the column\n",
      "    that indicates the class\"\"\"\n",
      "\n",
      "    # put the data in 10 buckets\n",
      "    numberOfBuckets = 10\n",
      "    data = {}\n",
      "    # first read in the data and divide by category\n",
      "    with open(filename) as f:\n",
      "        lines = f.readlines()\n",
      "    for line in lines:\n",
      "        if separator != '\\t':\n",
      "            line = line.replace(separator, '\\t')\n",
      "        # first get the category\n",
      "        category = line.split()[classColumn]\n",
      "        data.setdefault(category, [])\n",
      "        data[category].append(line)\n",
      "    # initialize the buckets\n",
      "    buckets = []\n",
      "    for i in range(numberOfBuckets):\n",
      "        buckets.append([])       \n",
      "    # now for each category put the data into the buckets\n",
      "    for k in data.keys():\n",
      "        #randomize order of instances for each class\n",
      "        random.shuffle(data[k])\n",
      "        bNum = 0\n",
      "        # divide into buckets\n",
      "        for item in data[k]:\n",
      "            buckets[bNum].append(item)\n",
      "            bNum = (bNum + 1) % numberOfBuckets\n",
      "\n",
      "    # write to file\n",
      "    for bNum in range(numberOfBuckets):\n",
      "        f = open(\"%s-%02i\" % (bucketName, bNum + 1), 'w')\n",
      "        for item in buckets[bNum]:\n",
      "            f.write(item)\n",
      "        f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#integrating 10-fold and buckets in classifier\n",
      "class Classifier:\n",
      "    def __init__(self, bucketPrefix, testBucketNumber, dataFormat):\n",
      "        self.bucketPrefix = bucketPrefix\n",
      "        self.bucketNumber = testBucketNumber\n",
      "        self.medianAndDeviation = []\n",
      "        self.format = dataFormat.strip().split('\\t')\n",
      "        self.data = []\n",
      "        for i in range(1,11):\n",
      "            if i != testBucketNumber:\n",
      "                filename = bucketPrefix+\"-0\"+str(i)\n",
      "                f = open(filename)\n",
      "                lines = f.readlines()\n",
      "                f.close()\n",
      "                for line in lines[1:]:\n",
      "                    fields = line.strip().split('\\t')\n",
      "                    ignore, vector = [], []\n",
      "                    for i in range(len(fields)):\n",
      "                        if self.format[i] == 'num':\n",
      "                            vector.append(float(fields[i]))\n",
      "                        elif self.format[i] == 'comment':\n",
      "                            ignore.append(fields[i])\n",
      "                        elif self.format[i] == 'class': \n",
      "                            classification = fields[i]\n",
      "                    self.data.append((classification, vector, ignore))\n",
      "        self.rawData = list(self.data)\n",
      "        self.vlen = len(self.data[0][1])\n",
      "        self.normalizeAllColumns()\n",
      "        \n",
      "    def getMedian(self, arr):\n",
      "        arr.sort()\n",
      "        l = len(arr)\n",
      "        if l % 2 == 1:\n",
      "            return arr[l//2]\n",
      "        else:\n",
      "            return (arr[l//2]+arr[l//2-1])/float(2)\n",
      "        \n",
      "    def getAbsoluteStandardDeviation(self, arr, median):\n",
      "        s = 0\n",
      "        for a in arr: s += abs(a-median)\n",
      "        return s/len(arr)\n",
      "    \n",
      "    def normalizeColumn(self, i):\n",
      "        col = [tup[1][i] for tup in self.data]\n",
      "        med = self.getMedian(col)\n",
      "        asd = self.getAbsoluteStandardDeviation(col, med)\n",
      "        self.medianAndDeviation.append((med,asd))\n",
      "        for tup in self.data: tup[1][i] = (tup[1][i] - med)/float(asd)\n",
      "    \n",
      "    def normalizeAllColumns(self):\n",
      "        for i in xrange(self.vlen): \n",
      "            self.normalizeColumn(i)\n",
      "            \n",
      "    def distance(self, vt1, vt2, k =1): \n",
      "        return sum(map (lambda v1,v2: abs(v1-v2)**k, vt1, vt2))**(1/float(k))\n",
      "    \n",
      "    def nearestNeighbor(self, itemVector):\n",
      "        distances = []\n",
      "        for item in self.data:\n",
      "            vector = item[1]\n",
      "            distances.append((self.distance(vector, itemVector), item))\n",
      "        distances.sort()\n",
      "        return distances\n",
      "\n",
      "    def normalizeVector(self, v):\n",
      "        # only works if median and asd in self.medianandasd\n",
      "        vector = list(v)\n",
      "        for i in range(len(vector)):\n",
      "            (median, asd) = self.medianAndDeviation[i]\n",
      "            vector[i] = (vector[i]-median)/float(asd)\n",
      "        return vector\n",
      "    \n",
      "    def classify(self, vector):\n",
      "        vector = self.normalizeVector(vector)\n",
      "        nearest = self.nearestNeighbor(vector)\n",
      "        return nearest[0][1][0]\n",
      "\n",
      "    def testBucket(self):\n",
      "        bucketNumber = self.bucketNumber\n",
      "        # confusion matrix\n",
      "        matrix = {}\n",
      "        filename = \"{0}-{1}\".format(self.bucketPrefix,'0'+str(bucketNumber))\n",
      "        f = open(filename)\n",
      "        lines = f.readlines()\n",
      "        f.close()\n",
      "        for line in lines:\n",
      "            data = line.strip().split('\\t')\n",
      "            vector, classInColumn = [], -1\n",
      "            for i in range(len(self.format)):\n",
      "                if self.format[i] == 'num': vector.append(float(data[i]))\n",
      "                elif self.format[i] == 'class': classInColumn = i\n",
      "            realClass = data[classInColumn]\n",
      "            classifiedAs = self.classify(vector)\n",
      "            matrix.setdefault(realClass, {})\n",
      "            matrix[realClass].setdefault(classifiedAs, 0)\n",
      "            matrix[realClass][classifiedAs] += 1\n",
      "        return matrix\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = Classifier('data/ch5_classification2/mpgData/mpgData',2, \"class\\tnum\\tnum\\tnum\\tnum\\tnum\\tcomment\")\n",
      "c.testBucket()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "{'10': {'15': 2},\n",
        " '15': {'15': 5, '20': 4},\n",
        " '20': {'15': 2, '20': 4, '25': 3, '30': 1},\n",
        " '25': {'20': 1, '25': 5, '30': 2},\n",
        " '30': {'20': 2, '25': 1, '30': 2, '35': 1, '40': 1},\n",
        " '35': {'25': 2, '40': 1, '45': 1},\n",
        " '40': {'35': 1},\n",
        " '45': {'45': 1}}"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tenfold(bucketPrefix, dataFormat):\n",
      "    results = {}\n",
      "    for i in range(1, 11):\n",
      "        c = Classifier(bucketPrefix, i, dataFormat)\n",
      "        t = c.testBucket()\n",
      "        for (key, value) in t.items():\n",
      "            results.setdefault(key, {})\n",
      "            for (ckey, cvalue) in value.items():\n",
      "                results[key].setdefault(ckey, 0)\n",
      "                results[key][ckey] += cvalue\n",
      "                \n",
      "    # now print results\n",
      "    categories = list(results.keys())\n",
      "    categories.sort()\n",
      "    print(   \"\\n       Classified as: \")\n",
      "    header =    \"        \"\n",
      "    subheader = \"      +\"\n",
      "    for category in categories:\n",
      "        header += category + \"   \"\n",
      "        subheader += \"----+\"\n",
      "    print (header)\n",
      "    print (subheader)\n",
      "    total = 0.0\n",
      "    correct = 0.0\n",
      "    for category in categories:\n",
      "        row = category + \"    |\"\n",
      "        for c2 in categories:\n",
      "            if c2 in results[category]:\n",
      "                count = results[category][c2]\n",
      "            else:\n",
      "                count = 0\n",
      "            row += \" %2i |\" % count\n",
      "            total += count\n",
      "            if c2 == category:\n",
      "                correct += count\n",
      "        print(row)\n",
      "    print(subheader)\n",
      "    print(\"\\n%5.3f percent correct\" %((correct * 100) / total))\n",
      "    print(\"total of %i instances\" % total)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tenfold('data/ch5_classification2/mpgData/mpgData', \"class\\tnum\\tnum\\tnum\\tnum\\tnum\\tcomment\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "       Classified as: \n",
        "        10   15   20   25   30   35   40   45   \n",
        "      +----+----+----+----+----+----+----+----+\n",
        "10    |  3 | 10 |  0 |  0 |  0 |  0 |  0 |  0 |\n",
        "15    |  3 | 68 | 14 |  1 |  0 |  0 |  0 |  0 |\n",
        "20    |  0 | 14 | 66 |  9 |  5 |  1 |  1 |  0 |\n",
        "25    |  0 |  1 | 14 | 35 | 21 |  6 |  1 |  1 |\n",
        "30    |  0 |  1 |  3 | 17 | 21 | 14 |  5 |  2 |\n",
        "35    |  0 |  0 |  2 |  8 |  9 | 14 |  4 |  1 |\n",
        "40    |  0 |  0 |  1 |  0 |  5 |  5 |  0 |  0 |\n",
        "45    |  0 |  0 |  0 |  2 |  1 |  1 |  0 |  2 |\n",
        "      +----+----+----+----+----+----+----+----+\n",
        "\n",
        "53.316 percent correct\n",
        "total of 392 instances\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "How good is a classifier? \n",
      "Kappa Statistics\n",
      "Compute a matrix of expected count (similar to chi-squared test)\n",
      "P(r) = P(correct in expected matrix)\n",
      "P(c) = P(correct in classifier)\n",
      "K = p(c) - p(r)/(1 - p(r))\n",
      "K < 0 - classifier makes it worse than chance lol\n",
      "K < 0.2 - ok\n",
      "K < 0.4 - fair\n",
      "k < 0.6 - good \n",
      "k < 0.8 - v good\n",
      "k < 1 - near perfect"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "One way to improve our current nearest neighbor approach is instead of looking at one nearest neighbor we look at a number of nearest neighbors\u2014k nearest neighbors or kNN. the class can be predicted on the basis of votes if the class is discrete. If the class is contrinous, we can use the distance as a proportion. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def knn(self, itemVector):\n",
      "    \"\"\"returns the predicted class of itemVector using k Nearest Neighbors\"\"\"\n",
      "    # changed from min to heapq.nsmallest to get the\n",
      "    # k closest neighbors\n",
      "    neighbors = heapq.nsmallest(self.k,[(self.manhattan(itemVector, item[1]), item) for item in self.data])\n",
      "    # each neighbor gets a vote\n",
      "    results = {}\n",
      "    for neighbor in neighbors:\n",
      "        theClass = neighbor[1][0] \n",
      "        results.setdefault(theClass, 0) \n",
      "        results[theClass] += 1\n",
      "    resultList = sorted([(i[1], i[0]) for i in results.items()], reverse=True)\n",
      "    #get all the classes that have the maximum votes\n",
      "    maxVotes = resultList[0][0]\n",
      "    possibleAnswers = [i[1] for i in resultList if i[0] == maxVotes] \n",
      "    # randomly select one of the classes that received the max votes answer = random.choice(possibleAnswers)\n",
      "    return( answer)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "^KNN for a discrete class classifier"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Applications of KNN:\n",
      "1. recommending items at Amazon\n",
      "2. assessing consumer credit risk\n",
      "3. face recog"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}