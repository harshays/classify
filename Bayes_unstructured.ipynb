{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes and unstructured text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ h_{map} = argmax_{h \\in H} P(D | h) P(h) $"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This can be used with unstructured text using 'bag-of-words' i.e text as a word frequency dict. -> training corpius -> classify text.\n",
    "\n",
    "\n",
    "o determine all documents' |vocab| -> number of distinct words + bag of words of main vocab \n",
    "\n",
    "\n",
    "o combine same class documents in one file\n",
    "\n",
    "\n",
    "o bag of words of each cumulative class doc (word wk has nk occurences)\n",
    "\n",
    "\n",
    "o for each word P(word | class) = (nk+1)/(n+|vocab|)\n",
    "\n",
    "\n",
    "o use sum of log(P(A)) since products P(A) becomes v small\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### News Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Remove all stop words (depends on type of data though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def getStopWord(l=100):\n",
    "    return list(filter(lambda x: len(x) <= l, stopwords.words('english')))\n",
    "\n",
    "# returns 57 stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Class for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import os, math\n",
    "class BayesTextTrain(object):\n",
    "    def __init__(self, tpath = \"/data/ch7_unstructured/20news-bydate/20news-bydate-train/\"):\n",
    "        self.join = os.path.join\n",
    "        self.vocab = defaultdict(int)\n",
    "        self.classVocab = defaultdict(lambda: defaultdict)\n",
    "        self.stopwords = set(getStopWord())\n",
    "        self.stopwords.add('')\n",
    "        self.train_path = tpath\n",
    "        self.test_path = \"/data/ch7_unstructured/20news-bydate/20news-bydate-test/\" # lazy\n",
    "        self.classes = BayesTextTrain._getfiles(\".\"+self.train_path) # 20 classes\n",
    "        self.priors = defaultdict(lambda: defaultdict(int))\n",
    "        self.matrix = defaultdict(lambda: defaultdict(int))\n",
    "        self.acc = [0,0] # correct and wrong\n",
    "        \n",
    "    @staticmethod\n",
    "    def _getfiles(directory):\n",
    "        return os.listdir(directory)\n",
    "    \n",
    "    \n",
    "    def _filterContent(self,c):\n",
    "        c = c.lower().split(\"lines:\")[-1].split()\n",
    "        def trimit(w):\n",
    "            ew = set(\"/\\<>&=!?^+*()[]{}-.%\")\n",
    "            return filter(lambda x: x not in ew, w)\n",
    "        c = map(lambda x: trimit(x), filter(lambda x: x not in self.stopwords and \"@\" not in x and len(x) > 2, c))\n",
    "        return c\n",
    "\n",
    "    def _countClass(self, clas):\n",
    "        classCounter = defaultdict(int)\n",
    "        pth = os.getcwd()+self.join(self.train_path, clas)\n",
    "        files = BayesTextTrain._getfiles(pth)\n",
    "        for afile in files:\n",
    "            filepth = self.join(pth, afile)\n",
    "            with open(filepth, 'r+') as f:\n",
    "                content = self._filterContent(f.read())\n",
    "                for w in content: classCounter[w]+=1\n",
    "        \n",
    "        self.classVocab[clas] = classCounter\n",
    "        for k,v in classCounter.items(): self.vocab[k] += v\n",
    "    \n",
    "    def train(self):\n",
    "        for clas in self.classes: self._countClass(clas)\n",
    "        for clas in self.classes: self._calcProbClass(clas)\n",
    "        \n",
    "    def _calcProbClass(self,clas):\n",
    "        n = len(self.vocab)\n",
    "        vocab = self.classVocab[clas]\n",
    "        for key, val in vocab.items():\n",
    "            self.priors[clas][key] = (val+1)/float(self.vocab[key]+n)\n",
    "            cclas = clas\n",
    "            if clas != cclas:\n",
    "                print clas\n",
    "                cclas = clas\n",
    "                \n",
    "    def classify(self,clas, article):\n",
    "        pth = os.getcwd()+self.join(self.test_path, clas+\"/\"+str(article))\n",
    "        with open(pth,'r+') as f:\n",
    "            l = map(lambda x: [0,x], self.classes)\n",
    "            content = self._filterContent(f.read())\n",
    "            for word in content:\n",
    "                for c in l:\n",
    "                    if self.priors[c[1]][word] == 0: continue\n",
    "                    c[0] += math.log(self.priors[c[1]][word])\n",
    "        return min(l)[-1]\n",
    "    \n",
    "    def test(self):\n",
    "        for clas in self.classes:\n",
    "            pth = self.join(os.getcwd()+\"/\"+self.test_path,clas)\n",
    "            files = self._getfiles(pth)\n",
    "            for f in files:\n",
    "                predictClass = self.classify(clas, f)\n",
    "                if (clas == predictClass): self.acc[0] += 1\n",
    "                else: self.acc[1] += 1\n",
    "                self.matrix[clas][predictClass] += 1\n",
    "        \n",
    "    \n",
    "    def accuracy(self):\n",
    "        print self.acc[0]/float(sum(self.acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = BayesTextTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.train() # takes ~2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603956452469\n"
     ]
    }
   ],
   "source": [
    "test.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "189 2   2   3   0   1   3   0   7   0   0   5   0   4   10  19  1   9   8   56  \n",
      "5   187 12  14  12  34  25  7   3   3   5   16  20  10  29  2   1   2   1   1   \n",
      "4   27  121 40  24  25  51  3   9   1   1   10  10  23  25  0   5   2   11  2   \n",
      "1   12  60  160 34  6   69  2   2   1   0   3   32  4   4   0   0   0   0   2   \n",
      "4   28  10  13  191 3   54  6   12  2   5   8   20  16  11  0   0   0   2   0   \n",
      "2   52  17  17  7   228 12  3   3   1   2   10  6   7   15  5   0   2   4   2   \n",
      "6   12  13  20  21  1   225 13  10  3   11  6   17  7   10  1   4   4   3   3   \n",
      "2   7   1   2   0   2   29  255 39  0   2   4   8   9   17  2   9   0   3   5   \n",
      "2   3   0   0   1   2   13  23  334 0   2   0   2   5   0   0   6   2   2   1   \n",
      "1   4   0   1   1   1   13  3   11  286 21  2   3   13  5   3   6   4   14  5   \n",
      "1   2   1   1   0   0   22  0   7   15  321 2   2   3   7   2   2   3   5   3   \n",
      "5   8   5   4   5   4   16  1   2   0   2   263 7   4   11  3   28  10  10  8   \n",
      "2   15  8   14  9   1   39  20  11  4   3   12  189 18  37  0   3   2   2   4   \n",
      "11  8   0   1   2   2   9   6   12  2   4   6   7   263 17  13  10  7   4   12  \n",
      "1   6   1   3   0   6   9   4   4   2   2   3   7   14  307 0   8   4   8   5   \n",
      "22  1   1   1   1   1   0   0   2   1   0   2   1   7   7   236 3   6   12  94  \n",
      "7   0   0   0   0   2   0   3   3   0   3   9   2   6   10  4   214 3   33  65  \n",
      "30  1   0   0   0   0   2   0   0   2   0   1   0   1   1   12  12  286 24  4   \n",
      "20  0   0   0   4   1   1   3   2   2   1   8   1   11  14  6   39  7   153 37  \n",
      "29  2   1   2   1   1   2   4   3   1   2   5   1   6   5   12  14  7   12  141\n"
     ]
    }
   ],
   "source": [
    "for clas in test.classes:\n",
    "    print \"\"\n",
    "    for clas2 in test.classes:\n",
    "        n = test.matrix[clas][clas2]\n",
    "        print str(n) + (3-len(str(n)))*\" \","
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
