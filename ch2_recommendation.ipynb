{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Numerati : Data mining for programmers"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Getting started with Recommendation Systems (Chapter 2)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Collaborative fitering - type of recommendation system. Example - Amazon customers also bought & Spotify recommended. first task is to find the person/feature that is closest/most similar to the user's preferences. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Manhattan distance $|x1-x2|+|y1-y2|$, Euclidean distance $\\sqrt{(x1-x2)^2+(y1-y2)^2}$, this can applied to N dimensions. However, this work only when there are no missing values. This can be generalized to the Minkowski distance metric $(\\sum{|p-q|^r})^\\frac{1}{r}$. Manhattan is minkowsi r =1 and euclidean minkowski r -2. Greater the r, more a large differnce in one dimension will infludnece the total difference. makes sense."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "def manhattan(rat1,rat2):\n",
      "    distance = 0\n",
      "    for k1 in rat1:\n",
      "        if k1 in rat2:\n",
      "            distance += math.fabs(rat1[k1]-rat2[k2])\n",
      "    return distance\n",
      "\n",
      "def minkowski(rat1,rat2,r):\n",
      "    assert r >= 1\n",
      "    distance = 0\n",
      "    commonRatings = False\n",
      "    for k1 in rat1:\n",
      "        if k1 in rat2:\n",
      "            commonRatings = True\n",
      "            distance += (math.fabs(rat1[k1]-rat2[k1]))**r\n",
      "    if commonRatings:\n",
      "        return float(distance**float(1/r))\n",
      "    else:\n",
      "        return 0\n",
      "\n",
      "def nearestNeighbor(user,allusers,r=1):\n",
      "    #manhattan is the default\n",
      "    distances = []\n",
      "    for u in allusers:\n",
      "        if u != user:\n",
      "            distance = minkowski(allusers[user],allusers[u],r)\n",
      "            distances.append((distance,u))\n",
      "    distances.sort()\n",
      "    return distances\n",
      "\n",
      "def makeRecommendation(user,users):\n",
      "    recs = []\n",
      "    neighbors = nearestNeighbor(user,users)\n",
      "    bestmatch = neighbors[0][1]\n",
      "    bestmatchrat = users[bestmatch]\n",
      "    for k in bestmatchrat:\n",
      "        if k not in user:\n",
      "            recs.append((k,bestmatchrat[k]))\n",
      "    return sorted(recs,key=lambda atup: atup[1],reverse=True)\n",
      "# edge cases if user and nearNeighbor have same exact set or if user has an empty set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "However, every user has a different variables and mean for average ratings. Therefore, ignoring this can increase inaccuracy. This can be solved using Pearson Correlation Coefficient - measures the correlation between 2 variables (for eg, ratings of two users). The formula used in the code is an approximation to the actual formula, which requires two passes to compute mean first."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from math import sqrt\n",
      "def pearson(rating1, rating2):\n",
      "    sum_xy = 0\n",
      "    sum_x = 0\n",
      "    sum_y = 0\n",
      "    sum_x2 = 0\n",
      "    sum_y2 = 0\n",
      "    n = 0\n",
      "    for key in rating1:\n",
      "        if key in rating2:\n",
      "            n += 1\n",
      "            x = rating1[key]\n",
      "            y = rating2[key]\n",
      "            sum_xy += x*y\n",
      "            sum_x += x\n",
      "            sum_y += y\n",
      "            sum_x2 += x**2\n",
      "            sum_y2 += y**2\n",
      "    denominator = sqrt(sum_x2 - (sum_x**2)/float(n))*sqrt(sum_y2 - (sum_y**2)/float(n))\n",
      "    if denominator == 0:\n",
      "        return 0\n",
      "    else:\n",
      "        return (sum_xy - (sum_x * sum_y)/n)/denominator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0,\n",
      "                      \"Norah Jones\": 4.5, \"Phoenix\": 5.0,\n",
      "                      \"Slightly Stoopid\": 1.5,\n",
      "                      \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0},\n",
      "         \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5,\n",
      "                 \"Deadmau5\": 4.0, \"Phoenix\": 2.0,\n",
      "                 \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},\n",
      "         \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0,\n",
      "                  \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \"Phoenix\": 5,\n",
      "                  \"Slightly Stoopid\": 1.0},\n",
      "         \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0,\n",
      "                 \"Deadmau5\": 4.5, \"Phoenix\": 3.0,\n",
      "                 \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,\n",
      "                 \"Vampire Weekend\": 2.0},\n",
      "         \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0,\n",
      "                    \"Norah Jones\": 4.0, \"The Strokes\": 4.0,\n",
      "                    \"Vampire Weekend\": 1.0},\n",
      "         \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0,\n",
      "                     \"Norah Jones\": 5.0, \"Phoenix\": 5.0,\n",
      "                     \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0,\n",
      "                     \"Vampire Weekend\": 4.0},\n",
      "        \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0, \"Norah Jones\": 2.0, \"Phoenix\": 5.0,\n",
      "                     \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},\n",
      "\n",
      "        \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0,\n",
      "             \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5,\"The Strokes\":3.0} }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cosine Similarity is used mainly in text mining, but sometimes also in collaborative filtering. Example - recommendations on number of times a song is played by a user. protip: data is sparse when the non-zero terms are fewer. cosine similarity is $\\frac{\\sum{x*y}}{|x|*|y|}$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cosineSimilarity(user1,user2):\n",
      "    modx,mody,sxy=0,0,0\n",
      "    for k in user1:\n",
      "        if k in user2:\n",
      "            user2val = user2[k]\n",
      "        else:\n",
      "            user2val = 0\n",
      "        modx += user1[k]**2\n",
      "        mody += user2val**2\n",
      "        sxy += (user1[k]*user2val)\n",
      "    modx = modx**0.5\n",
      "    mody = mody**0.5\n",
      "    return sxy/float(modx*mody)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data1 = {'bt':3.5,'bb':2,'nj':4.5,'ph':5,'ss':1.5,'ts':2.5,'vw':2}\n",
      "data2 = {'bt':3,'nj':5,'ph':4,'ss':2.5,'ts':3}\n",
      "print \"Manhattan : \"+str(minkowski(data1,data2,1))\n",
      "print \"Euclidean : \"+str(minkowski(data1,data2,2))\n",
      "print \"Pearson : \"+str(pearson(users['Hailey'],users['Sam']))\n",
      "print \"Cosine Coeff : \"+str(cosineSimilarity(data1,data2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Manhattan : 3.5\n",
        "Euclidean : 1.0\n",
        "Pearson : 0\n",
        "Cosine Coeff : 0.924627943221\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "if the data is based on the user's individual scale, user Pearson\n",
      "if the data is dense (opp of sparse), use minkowski\n",
      "if the data is sparse, use cosine\n",
      "However, similarity through distance in general in only accurate if the n is large and the 2 parameters have enough similarities\n",
      "Also, relying only on the single most common person is sort of risky business. Hence, the mighty K-nearest neighbor"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "K nearest neighbors:\n",
      "the best value of k is application specific.\n",
      "kNN:\n",
      "1. compute the k nearest neighbors' correlation coefficients \n",
      "2. get the influence factor for every neighbor: r/sum_of_all_r (r is corr)\n",
      "3. for every reccomendation, the final rating of the recommendation is the sum of the weighted ratings"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "def nearestNeighborPearson(user,allusers):\n",
      "    distances = []\n",
      "    cor = 0\n",
      "    for u in allusers:\n",
      "        if u != user:\n",
      "            cor = pearson(allusers[user],allusers[u])\n",
      "            distances.append((cor,u))\n",
      "    distances.sort()\n",
      "    return sorted(distances,key=lambda x: x[0],reverse=True)\n",
      "\n",
      "#nearestNeighborPearson('Hailey',users)\n",
      "def getCommonKeys(names,db):\n",
      "    keys = set()\n",
      "    for n in names:\n",
      "        nn = db[n]\n",
      "        for k in nn:\n",
      "            keys.add(k)\n",
      "    return keys\n",
      "\n",
      "\n",
      "def KNN(user,allusers,k=5,fn=nearestNeighbor):\n",
      "    neighbors = fn(user,allusers)[:k]\n",
      "    neighbors_names = [n[1] for n in neighbors]\n",
      "    neighbors_pearson = [n[0] for n in neighbors] #warning : it is not actually pearson. just distance. sorry.\n",
      "    sum_pearson = sum(neighbors_pearson)\n",
      "    neighbors_strength = [n/float(sum_pearson) for n in neighbors_pearson]\n",
      "    recommendations = defaultdict(int)\n",
      "    commonKeys = getCommonKeys(neighbors_names,allusers)\n",
      "    for k in commonKeys:\n",
      "        for x,n in enumerate(neighbors_names):\n",
      "            nn = allusers[n]\n",
      "            if k in nn and k not in allusers[user]:\n",
      "                s = neighbors_strength[x]\n",
      "                kv = nn[k]\n",
      "                recommendations[k] += s*kv\n",
      "    return sorted(list((recommendations[k],k) for k in recommendations),key=lambda x:x[0],reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 82
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "with open('/Users/HarshayShah/Documents/code/python/numerati/ch2/Movie_Ratings.csv','rb') as f:\n",
      "    fcsv = list(csv.reader(f,delimiter=\",\"))\n",
      "    users,movies,db = fcsv[0][1:],[l[0] for l in fcsv][1:],{}\n",
      "    for u in users: db[u] = {}\n",
      "        \n",
      "    movie_ratings = []\n",
      "    for l in fcsv:\n",
      "        mratings = []\n",
      "        for i in l[1:]:\n",
      "            mratings.append(i)\n",
      "        movie_ratings.append(mratings)\n",
      "    movie_ratings = movie_ratings[1:]\n",
      "    \n",
      "    for i,m in enumerate(movies):\n",
      "        for j,u in enumerate(users):\n",
      "            if movie_ratings[i][j] != '': db[u].update({m:int(movie_ratings[i][j])})\n",
      "    # db complete\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "KNN('Matt',db,k=3,fn=nearestNeighborPearson)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "[(4.68469376978551, 'Gladiator'),\n",
        " (4.36938753957102, 'Star Wars'),\n",
        " (4.3263729551756365, 'Dodgeball'),\n",
        " (4.011066724961147, 'Old School'),\n",
        " (4.0, 'The Matrix'),\n",
        " (4.0, 'Scarface'),\n",
        " (3.423468848927551, 'Shawshank Redemption'),\n",
        " (3.31530623021449, 'Avatar'),\n",
        " (3.0970958937519146, 'The Dark Knight'),\n",
        " (2.738775079142041, 'Pulp Fiction'),\n",
        " (2.251410511346016, 'Braveheart'),\n",
        " (2.1179770282250043, 'Blade Runner'),\n",
        " (1.9680521405657632, 'Jaws'),\n",
        " (1.7055749042586001, 'Village'),\n",
        " (0.6736270448243633, 'Pootie Tang')]"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    }
   ],
   "metadata": {}
  }
 ]
}