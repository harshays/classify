<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <title>Classify by harshays</title>
  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1>Classify</h1>
          <h2>Learning the basics of classification in Python.</h2>
        </header>

        <section id="downloads" class="clearfix">
          <a href="https://github.com/harshays/classify/zipball/master" id="download-zip" class="button"><span>Download .zip</span></a>
          <a href="https://github.com/harshays/classify/tarball/master" id="download-tar-gz" class="button"><span>Download .tar.gz</span></a>
          <a href="https://github.com/harshays/classify" id="view-on-github" class="button"><span>View on GitHub</span></a>
        </section>

        <hr>

        <section id="main_content">
          <h3>
<a id="classify" class="anchor" href="#classify" aria-hidden="true"><span class="octicon octicon-link"></span></a>Classify.</h3>

<p>This repository consists of IPython tutorials aimed at newbies who want to understand how classification works. Each notebook covers a topic, explained in text and Python code. Most of the content has been derived from the website, guidetodatamining.com. </p>

<pre><code>$ cd classify/
$ ipython notebook
</code></pre>

<h3>
<a id="notebooks" class="anchor" href="#notebooks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Notebooks</h3>

<hr>

<h5>
<a id="introduction-to-recommendation-systems" class="anchor" href="#introduction-to-recommendation-systems" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="http://nbviewer.ipython.org/github/harshays/classify/blob/master/recommendation_intro.ipynb">Introduction to recommendation systems</a>
</h5>

<p>collaborative filtering. distances. minkowski distance metric. Using pearson correlation &amp; cosine similarity to standardize user ratings.  dense and sparse data. basics of how kNN works.
<br></p>

<h5>
<a id="filtering" class="anchor" href="#filtering" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="http://nbviewer.ipython.org/github/harshays/classify/blob/master/collaborative_filtering.ipynb">Filtering</a>
</h5>

<p>Item-based filtering. Comparing it to collaborative filtering. Cosine similarity for items. Adjusting user ratings. Similarity matrix. Normalizing, denormalizing and predicting scores. Applying the weighted slope one algorithm. 
<br></p>

<h5>
<a id="classification" class="anchor" href="#classification" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="http://nbviewer.ipython.org/github/harshays/classify/blob/master/classification.ipynb">Classification</a>
</h5>

<p>comparing classification to filtering. Pandora music recommendation example. computing nearest neighbors using features. Normalizing using absolute standard deviation and standard score. Basics of training and testing data using a Classifier class.
<br></p>

<h5>
<a id="classification-ii" class="anchor" href="#classification-ii" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="http://nbviewer.ipython.org/github/harshays/classify/blob/master/KNN.ipynb">Classification II</a>
</h5>

<p>dividing data into 'buckets'. 10-fold cross validation. confusion matrix. Kappa statistic to evaluate a classifier's acuuracy. 
<br></p>

<h5>
<a id="naïve-bayes" class="anchor" href="#na%C3%AFve-bayes" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="http://nbviewer.ipython.org/github/harshays/classify/blob/master/naive_bayes.ipynb">Naïve Bayes</a>
</h5>

<p>Intro to probabilistic classification. lazy learner versus eager learner. Bayesian probability. Deriving the basic algorithm for naive bayes classification. Applying naïve bayes to house votes dataset. To be continued. 
<br></p>

<h5>
<a id="naïve-bayes-with-unstructured-data" class="anchor" href="#na%C3%AFve-bayes-with-unstructured-data" aria-hidden="true"><span class="octicon octicon-link"></span></a><a href="http://nbviewer.ipython.org/github/harshays/classify/blob/master/Bayes_unstructured.ipynb">Naïve Bayes with unstructured data</a>
</h5>

<p>bag of words. Prior probability with text. additive smoothing again. stop words vs no stop words. Text classification. Used naive bayes to classify the category of a news article. 
<br></p>

<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p>All credits go to Ron Zacharsk for working on guidetodatamining.com</p>
        </section>

        <footer>
          Classify is maintained by <a href="https://github.com/harshays">harshays</a><br>
          This page was generated by <a href="http://pages.github.com">GitHub Pages</a>. Tactile theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.
        </footer>

        
      </div>
    </div>
  </body>
</html>
