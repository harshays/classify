{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the nearest neighbor algorithms, it is difficult to quantify confidence about a classification. With stats, specifically bayesian methods, we can make probabilistic classifications. (refer to proababilistic programming ipython tutorial for bayesian methods and markov chains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest neighbor algorithms are lazy learners. After normalizing or standardizing trained data, they only go through the entire dataset when a vector needs to be classified. Conversely, bayesian methods are eager learners that analyze data & continously improve models. Since a model is already made, classifcation is way faster. (notes for basics of conditional probability not needed)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bayesian Stuff:\n",
    "\n",
    "P(h) - probability the some hypothesis h is true, called prior probability. BEFORE we have any evidence.\n",
    "e.g. P(has Mac) = 0.6 (evidence can be knowing if he has an iPhone)\n",
    "\n",
    "P(h | d) - posterior probabilty. P(h | d) is the probability that hypothesis h is true given the evidence d. \n",
    "e.g. P(has Mac | has iphone) will be different since we have evidence d\n",
    "\n",
    "Bayesian classifiers also require P(D) and P(D | h)\n",
    "\n",
    "P(D) - probability that some training data value will be observed. \n",
    "        P(8001abcd) - probability that a user lives @ 8001abcd zipcode\n",
    "P(D | h) - probability that training data value holds given hypothesis h is true)\n",
    "    p(8001abcd | dog) - probability that a user lives @8001abcd zipcode given that he/she has a pet dog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification example using Bayes max(P(gymnast, vector), P(basketball, vector), P(cyclist, vector)) where vector is the additional evidence - maximum a posteriori hyposthesis or $ h_{MAP} $\n",
    "\n",
    "  $ h_{MAP} = arg max_{h \\in H} P(h | D) $ where D is additional data/evidence and h is hypothesis\n",
    "  \n",
    "  also, $ h_{MAP} = arg max_{h \\in H} P(D | h) * P(h) $ using Bayes' theorem and removing the constant denominator $P(D)$\n",
    "  \n",
    "A naive bayes classifier computes P(h | D) and uses $h_{map}$:\n",
    "\n",
    "  $ P(class | F_{1}, F_{2}, ... , F_{n}) = \\large \\frac {P(F_{1}, F_{2}, ... , F_{n} | class) \\cdot P(class)} {P(F_{1} \\cap F_{2} ... \\cap F_{n})} $\n",
    "  \n",
    "  $ P(class | F_{1}, F_{2}, ... , F_{n}) = P(F_{1}, F_{2}, ... , F_{n} | class) \\cdot P(class) $\n",
    "  \n",
    "  $ P(class | F_{1}, F_{2}, ... , F_{n}) = P(class \\cap F_{1} \\cap F_{2} \\cap ... F_{n})  $      ---- > (A)\n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In (A), we can use the chain rule of a joint probability. Therefore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P(class \\cap F_{1} \\cap F_{2} \\cap ... F_{n}) = P(class) \\cdot P(F_{1} | class)  \\cdot P(F_{2} | class, F_{1}) \\cdot P(F_{3} | class, F_{1}, F_{2}) \\cdot ... \\cdot P(F_{n} | class, F_{1}, F_{2}, ... , F_{n-1})  $ ------> (B)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "However, naive bayes assumes that all features are independent of one another. Therefore, (A) can be simplified to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if features are independent:\n",
    "\n",
    "$ P(F_{1}, F_{2}, .. , F_{n} | class) = P(F_{1} | class) \\cdot P(F_{2} | class) \\cdot .. \\cdot P(F_{n} | class) $\n",
    "\n",
    "Therefore\n",
    "\n",
    "$ P(class | F_{1}, F_{2}, ... , F_{n}) = P(class) \\cdot P(F_{1} | class) \\cdot P(F_{2} | class) \\cdot .. \\cdot P(F_{n} | class) $\n",
    "\n",
    "$ P(C | F) = P(C) \\cdot \\prod_{n \\in N} {P(F_{x} | C)} $\n",
    "\n",
    "and classifier function:\n",
    "\n",
    "$ h_{NB} = argmax_{c \\in C} P(C) \\cdot \\prod_{n \\in N} {P(F_{x} | C)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']\n"
     ]
    }
   ],
   "source": [
    "house_votes_raw = []\n",
    "with open('data/ch6_naivebayes/house-votes/hv-01') as f:\n",
    "    house_votes_raw = f.readlines()\n",
    "house_votes = map(lambda x: x.strip().split('\\t'), house_votes_raw)\n",
    "house_votes_categories = ['class'] + ['f']*16\n",
    "print house_votes_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training data for naive bayes in python\n",
    "# 1. occurences and probability of each class 2. occurences and probability of each feature 3. P(feature|class)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "class BayesClassifier(object):\n",
    "    #assumes that data is broken into n buckets. use buckets in KNN notebook\n",
    "    def __init__(self,bucketPrefix,dataFormat,n_buckets):\n",
    "        #dataFormat in array form\n",
    "        self.bucketPrefix = bucketPrefix\n",
    "        self.dataFormat = dataFormat\n",
    "        self.n_buckets = n_buckets\n",
    "        self.raw_data = self.get_raw_data()\n",
    "        self.data = self.clean_raw_data()\n",
    "        self.priori = self.get_priori()\n",
    "        self.conditional_buckets = self.get_conditional()\n",
    "        \n",
    "        # structure of conditional bucket\n",
    "        # bucket -> class -> feature_no -> feature -> P(feature | class)\n",
    "        \n",
    "    def get_raw_data(self):\n",
    "        raw = []\n",
    "        for i in xrange(1,self.n_buckets+1):\n",
    "            filename, bucket_data = \"%s-%02i\" % (self.bucketPrefix, i), []\n",
    "            with open(filename) as f: bucket_data = map(lambda x: x.strip().split('\\t'),f.readlines())\n",
    "            raw.append(bucket_data)\n",
    "        return raw  \n",
    "    \n",
    "    def clean_raw_data(self):\n",
    "        buckets_data = []\n",
    "        for b,bucket in enumerate(self.raw_data):\n",
    "            bucket_data = {}\n",
    "            for arr in bucket:\n",
    "                C = \"\"\n",
    "                for i,data in enumerate(arr):\n",
    "                    if self.dataFormat[i] == \"class\":\n",
    "                        C = data\n",
    "                        bucket_data.setdefault(data,{})\n",
    "                        bucket_data[data].setdefault('count',0)\n",
    "                        bucket_data[data].setdefault('ignore',[])\n",
    "                        bucket_data[data]['count']+=1\n",
    "                for i,data in enumerate(arr):\n",
    "                    if self.dataFormat[i] == \"f\":\n",
    "                        bucket_data[C].setdefault(i,{})\n",
    "                        bucket_data[C][i].setdefault(data,0)\n",
    "                        bucket_data[C][i][data]+=1 \n",
    "                    elif self.dataFormat[i] == \"ignore\":\n",
    "                        bucket_data[C]['ignore'].append(data)\n",
    "            buckets_data.append(bucket_data)\n",
    "        return buckets_data\n",
    "    \n",
    "    def get_priori(self):\n",
    "        prioris = []\n",
    "        for i,bucket_data in enumerate(self.data):\n",
    "            priori, total = defaultdict(dict), 0\n",
    "            for cls, cls_info in bucket_data.items():\n",
    "                priori[cls] = self.data[i][cls]['count']\n",
    "                total += priori[cls]\n",
    "            for cls in priori.keys(): priori[cls] = priori[cls]/float(total)\n",
    "            prioris.append(priori)\n",
    "        return prioris\n",
    "    \n",
    "    def get_conditional(self):\n",
    "        conditional_buckets = []\n",
    "        for bucket in self.data: conditional_buckets.append(self._get_conditional_for_bucket(bucket))\n",
    "        return conditional_buckets\n",
    "    \n",
    "    def _get_conditional_for_bucket(self, b):\n",
    "        bucket = b.copy()\n",
    "        for cls in bucket.keys():\n",
    "            count = bucket[cls]['count']\n",
    "            for feature_no, features in bucket[cls].items():\n",
    "                if isinstance(feature_no, int):\n",
    "                    for feature in features.keys(): \n",
    "                        bucket[cls][feature_no][feature] /= float(count)\n",
    "        return bucket\n",
    "    \n",
    "    def classify(self, vector, bucketNumber):\n",
    "        data = self.conditional_buckets[bucketNumber]\n",
    "        priori = self.priori[bucketNumber]\n",
    "        #print data['republican'][1][vector[0]]\n",
    "        probabilities = []\n",
    "        for cls,cls_feature_dict in data.items():\n",
    "            prob = priori[cls]\n",
    "            for i,feature in enumerate(vector):\n",
    "                if feature in cls_feature_dict[i+1].keys():\n",
    "                    prob *= cls_feature_dict[i+1][feature]\n",
    "            probabilities.append((prob,cls))\n",
    "        return sorted(probabilities)[-1][-1]\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# d = BayesClassifier('data/ch6_naivebayes/house-votes/hv',house_votes_categories,10)\n",
    "# sample_vector = ['democrat', 'y', 'n', 'y', 'n', 'n', 'n', 'y', 'y', 'y', 'n', '', 'n', 'n', 'n', 'y', 'y']\n",
    "def _testClassifier(bucketPrefix, dataFormat, nBuckets, testBucketNumber):\n",
    "    d = BayesClassifier(bucketPrefix, dataFormat, nBuckets)\n",
    "    testBucket = d.raw_data[testBucketNumber]\n",
    "    correct, total = 0,0 \n",
    "    for i in range(nBuckets):\n",
    "        if i == testBucketNumber: continue\n",
    "        for test in testBucket:\n",
    "            real = test[0]\n",
    "            predict = d.classify(test[1:],i)\n",
    "            total += 1\n",
    "            if real == predict: correct += 1\n",
    "    return correct/float(total)\n",
    "\n",
    "def test(bucketPrefix, dataFormat, nBuckets):\n",
    "    accuracy = []\n",
    "    for i in range(nBuckets): accuracy.append(_testClassifier(bucketPrefix, dataFormat, nBuckets, i))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of classifier accuracy\n",
      "count    10.000000\n",
      "mean      0.861171\n",
      "std       0.080966\n",
      "min       0.748792\n",
      "25%       0.831019\n",
      "50%       0.841586\n",
      "75%       0.897672\n",
      "max       0.989899\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "accuracy = test('data/ch6_naivebayes/house-votes/hv', house_votes_categories, 10)\n",
    "pd_accuracy = pandas.Series(accuracy)\n",
    "print \"Summary of classifier accuracy\"\n",
    "print pd_accuracy.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the classifier has an accuracy of 86%. This can be improved though. Refer to notebook naïve_bayes2. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next notebook:\n",
    "\n",
    "1.pros and cons of normalizing. \n",
    "\n",
    "2. Using normal distribtion\n",
    "\n",
    "3. Implemening a pdf class to compute P(x|y) using functions\n",
    "\n",
    "4. Integrating improvements into existing BayesClassifier class\n",
    "\n",
    "5. Comparing KNN to Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
